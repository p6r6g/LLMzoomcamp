{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa9c8d1-28c4-4f32-b894-f0e63078efc7",
   "metadata": {},
   "source": [
    "<h1> Vector Search with Qdrant : </h1>\n",
    "\n",
    "<h2> Vector Search: </h2>\n",
    "Vector search replaces exact keyword matching with semantic similarity, enabling retrieval based on meaning.\n",
    "It excels in searching through diverse data types like text, images, audio, video, and code, even when phrasing or formats differ.\n",
    "It does that my converting words into number(vector embeddings), and the distance between two vectors in a 3D space gives them the meaning - words related to each other based on similarity and context are closer to each other.  It recognizes patterns and relationships between concepts, enabling search systems to retrieve the most relevant content, even when the phrasing differs, terminology varies, or no explicit keywords exist.\n",
    "\n",
    "<h2> Qdrant: </h2>\n",
    "Qdrant is a high-performance, open-source vector search engine built in Rust for scalable, production-grade applications.\n",
    "It offers advanced vector search capabilities beyond basic similarity, staying aligned with modern AI search trends.\n",
    "\n",
    "\n",
    "<h4>TLDR:</h4>\n",
    "Vector Search is excellent for semantic search to capture context and meaning behind words (and unstructured data) by relating language with maths(vectors and geometry), unlike syntactic search where strings are compared. and Qdrant is a vector search engine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f75b5-a79a-4e15-8b0d-ea151a24d6aa",
   "metadata": {},
   "source": [
    "running qdrant in a docker container (in github codespace):\n",
    "run in terminal:\n",
    "<!-- \n",
    "docker pull qdrant/qdrant\n",
    "\n",
    "docker run -p 6333:6333 -p 6334:6334 \\\n",
    "   -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "   qdrant/qdrant -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264e0686-0073-4b9e-aae3-2514b9973c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdrant-client package for python and fastembed for optimized embedding (data vectorization) designed for qdrant.\n",
    "\n",
    "!python -m pip install -q \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddac89-24e3-4411-93e6-c63d98e6a8ad",
   "metadata": {},
   "source": [
    "<h3>Step 1: Import required libraries and connect to Qdrant.</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93cc05aa-50c8-4dc1-9ede-94efe5a9fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa6be39-6909-41d7-b6ae-2aa9b498a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to local Qdrant instance\n",
    "client = QdrantClient(\"http://localhost:6333\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d9e5dd-2c88-4a7b-8a1f-a983ed0a5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e14735-c73a-4d3b-9354-f1d37143fb7e",
   "metadata": {},
   "source": [
    "<h3>Step 2: Study the dataset</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71c9eea-098f-4b8a-8b71-7683124bb160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#documents_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96be5ca-4227-47e9-95bf-bb456fc53e0c",
   "metadata": {},
   "source": [
    "As the data seems already cleaned and chunked (list of dictionaries of question-answer pairs), and is only English text. Next we decide on which fields to be used for vector search and which to be stored as metadata.\n",
    "Metadata is useful for filtering conditions. \n",
    "\n",
    "Since we are building a Q&A RAG system, it makes sense to store Answers (text) as embeddings and use vector search using the Question as a query.\n",
    "Filters like Course and Section could be stored as metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2151dd-152a-48c7-ac61-d96bfdfecf7e",
   "metadata": {},
   "source": [
    "<h3>Step 3: \n",
    "Choose the optimal embedding model with fastembed for our textual data</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730f6506-f61d-4b5a-892c-d5c310297101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding\n",
    "# TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e1d203-4cc7-4403-95b4-4c985a1f4d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.25,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.12,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "embedding_dimensionality = 512    # each vector will have a dimensionality of 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model['dim'] == embedding_dimensionality:\n",
    "        print(json.dumps(model, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4dae3f2-fa5b-4262-84d8-f8b53c8f63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "# like most dense embedding model, this one also measures semantic closeness through cosine similarity - angle between 2 vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd7e216-091f-4f65-a15c-83a1a5f8b9fb",
   "metadata": {},
   "source": [
    "<h3>Step 4: Creating a collection</h3>\n",
    "\n",
    "\n",
    "\n",
    "A collection is a named set of points that you can search within. A point is a record consisting of an ID, a vector, and an optional payload. \n",
    "Embeddings capture the semantic essence of the data, while the payload holds structured metadata.\n",
    "This metadata becomes especially useful when applying filters or sorting during search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542fd116-40d5-4ade-9ecc-3d8f14e36961",
   "metadata": {},
   "source": [
    "When creating a collection, we need to specify:\n",
    "\n",
    "1. Name: A unique identifier for the collection.\n",
    "2. Vector Configuration:\n",
    "    1. Size: The dimensionality of the vectors.\n",
    "    2. Distance Metric: The method used to measure similarity between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132b2542-365d-45a9-b729-567d085f1888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `zoomcamp-rag` already exists!\"},\"time\":0.002862137}'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedResponse\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m collection_name = \u001b[33m'\u001b[39m\u001b[33mzoomcamp-rag\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVectorParams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dimensionality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# dimensionality of the vectors\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDistance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOSINE\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# distance metric for similarity search\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/qdrant_client/qdrant_client.py:2386\u001b[39m, in \u001b[36mQdrantClient.create_collection\u001b[39m\u001b[34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, strict_mode_config, **kwargs)\u001b[39m\n\u001b[32m   2336\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create empty collection with given parameters\u001b[39;00m\n\u001b[32m   2337\u001b[39m \n\u001b[32m   2338\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2382\u001b[39m \u001b[33;03m    Operation result\u001b[39;00m\n\u001b[32m   2383\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2384\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) == \u001b[32m0\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_number\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshard_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2390\u001b[39m \u001b[43m    \u001b[49m\u001b[43msharding_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharding_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2395\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwal_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwal_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2398\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2400\u001b[39m \u001b[43m    \u001b[49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict_mode_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict_mode_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2402\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2403\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/qdrant_client/qdrant_remote.py:2815\u001b[39m, in \u001b[36mQdrantRemote.create_collection\u001b[39m\u001b[34m(self, collection_name, vectors_config, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, sparse_vectors_config, sharding_method, strict_mode_config, **kwargs)\u001b[39m\n\u001b[32m   2797\u001b[39m     init_from = GrpcToRest.convert_init_from(init_from)\n\u001b[32m   2799\u001b[39m create_collection_request = models.CreateCollection(\n\u001b[32m   2800\u001b[39m     vectors=vectors_config,\n\u001b[32m   2801\u001b[39m     shard_number=shard_number,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2812\u001b[39m     strict_mode_config=strict_mode_config,\n\u001b[32m   2813\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2815\u001b[39m result: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_collection_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2819\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m   2821\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mCreate collection returned None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/qdrant_client/http/api/collections_api.py:294\u001b[39m, in \u001b[36mSyncCollectionsApi.create_collection\u001b[39m\u001b[34m(self, collection_name, timeout, create_collection)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_collection\u001b[39m(\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    287\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    288\u001b[39m     timeout: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    289\u001b[39m     create_collection: m.CreateCollection = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    290\u001b[39m ) -> m.InlineResponse200:\n\u001b[32m    291\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    Create new collection with given parameters\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_for_create_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/qdrant_client/http/api/collections_api.py:96\u001b[39m, in \u001b[36m_CollectionsApi._build_for_create_collection\u001b[39m\u001b[34m(self, collection_name, timeout, create_collection)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[32m     95\u001b[39m     headers[\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInlineResponse200\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/qdrant_client/http/api_client.py:90\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, type_, method, url, path_params, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     89\u001b[39m request = \u001b[38;5;28mself\u001b[39m._client.build_request(method, url, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/qdrant_client/http/api_client.py:125\u001b[39m, in \u001b[36mApiClient.send\u001b[39m\u001b[34m(self, request, type_)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    124\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse.for_response(response)\n",
      "\u001b[31mUnexpectedResponse\u001b[39m: Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `zoomcamp-rag` already exists!\"},\"time\":0.002862137}'"
     ]
    }
   ],
   "source": [
    "collection_name = 'zoomcamp-rag'\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name = collection_name,\n",
    "    vectors_config = models.VectorParams(\n",
    "        size = embedding_dimensionality,    # dimensionality of the vectors\n",
    "        distance = models.Distance.COSINE   # distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c65cdb-2877-44d3-b21c-8ab7bd7726f1",
   "metadata": {},
   "source": [
    "<h3>Step 5: Create, Embed & Insert points into the collection.</h3>\n",
    "\n",
    "\n",
    "Points are the core data entities in Qdrant. Each point consists of:\n",
    "\n",
    "1. ID. A unique identifier. \n",
    "2. Vector. The embedding that represents the data point in vector space.\n",
    "3. Payload (optional). Additional metadata as key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1e61d-e8fe-4872-b9e3-a90a4a34e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating points\n",
    "\n",
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course['documents']:\n",
    "\n",
    "        point = models.PointStruct(\n",
    "            id = id,\n",
    "            vector = models.Document(text = doc['text'], model = model_handle),\n",
    "            payload = {\n",
    "                \"text\": doc['text'],\n",
    "                \"section\": doc['section'],\n",
    "                \"course\": course['course']\n",
    "            }\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17b8bc-0168-4dbd-b9eb-fbd41c650ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding and uploading the points\n",
    "\n",
    "# upsert is the combination of insert and update\n",
    "\n",
    "client.upsert(\n",
    "    collection_name = collection_name,\n",
    "    points = points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784c7c8-339a-42a0-bee0-245aa5745756",
   "metadata": {},
   "source": [
    "<h3>Study the data visually:</h3>\n",
    "\n",
    "Explore the uploaded data in the Qdrant Web UI at http://localhost:6333/dashboard to study semantic similarity visually.\n",
    "\n",
    "For example, using the Visualize tab in the zoomcamp-rag collection, we can view all answers to the course questions (948 points) and see how they group together by meaning, additionally coloured by the course type.\n",
    "\n",
    "To do that, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f9bc5-07f2-4516-9ba8-711f7c213bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"limit\": 948,\n",
    "#   \"color_by\": {\n",
    "#     \"payload\": \"course\"\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e70312d-952c-41b8-8ea1-2035b69fcb12",
   "metadata": {},
   "source": [
    "This 2D representation is the result of dimensionality reduction applied to jina-embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c7723-13d4-49ef-8e41-1f4a0c2fcdb7",
   "metadata": {},
   "source": [
    "<h3> Step 6: Running a similarity search</h3>\n",
    "\n",
    "\n",
    "\n",
    "<h4> how similarity search works:</h4>\n",
    "\n",
    "1. Qdrant compares the query vector to the stored vector, based on vector index, using the distance metric defined for similarity.\n",
    "\n",
    "2. The closest matches are returned based on similarity. Vector index is built for ANN (Approximate Nearest Neighbour) search, because building exact search is difficult for vector index since vectors can be really huge in size.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a29aa7-6951-40a7-b693-0781a38732c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "    \n",
    "    results = client.query_points(\n",
    "        \n",
    "        collection_name = collection_name,\n",
    "        \n",
    "        query = models.Document(    # embed the query text locally using \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text = query,\n",
    "            model = model_handle\n",
    "        ),\n",
    "        limit = limit,    # top closest matches\n",
    "        with_payload = True    # to get metadata in results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea842e-9740-4a8e-85b6-876eb50cda0d",
   "metadata": {},
   "source": [
    "Now, picking a random question from the course data. \n",
    "\n",
    "Also remember, we didn't upload/embed the questions to Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d8074fb-fa33-4072-9a03-73ca7b0452db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Problem description:  You might get an error \\u2018Invalid base64\\u2019 after running the \\u2018aws kinesis put-record\\u2019 command on your local machine. This might be the case if you are using the AWS CLI version 2 (note that in the video 4.4, around 57:42, you can see a warning since the instructor is using v1 of the CLI.\\nSolution description: To get around this, pass the argument \\u2018--cli-binary-format raw-in-base64-out\\u2019. This will encode your data string into base64 before passing it to kinesis\\nAdded by M\",\n",
      "  \"section\": \"Module 4: Deployment\",\n",
      "  \"question\": \"\\u2018Invalid base64\\u2019 error after running `aws kinesis put-record`\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course['documents'])\n",
    "print(json.dumps(course_piece, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3491f89-5bdd-4fcd-90c1-e1c51bdea7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=901, version=1, score=0.9338168, payload={'text': 'Problem description:  You might get an error ‘Invalid base64’ after running the ‘aws kinesis put-record’ command on your local machine. This might be the case if you are using the AWS CLI version 2 (note that in the video 4.4, around 57:42, you can see a warning since the instructor is using v1 of the CLI.\\nSolution description: To get around this, pass the argument ‘--cli-binary-format raw-in-base64-out’. This will encode your data string into base64 before passing it to kinesis\\nAdded by M', 'section': 'Module 4: Deployment', 'course': 'mlops-zoomcamp'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = search(course_piece['question'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37367d-0a20-4476-a9b7-86d04e579da1",
   "metadata": {},
   "source": [
    "Now, comparing the retrieved answer with the original answer for our randomly selected question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5756137e-4134-47b7-a955-91f4c7618fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "‘Invalid base64’ error after running `aws kinesis put-record`\n",
      "\n",
      "Top Retrieved Answer:\n",
      "Problem description:  You might get an error ‘Invalid base64’ after running the ‘aws kinesis put-record’ command on your local machine. This might be the case if you are using the AWS CLI version 2 (note that in the video 4.4, around 57:42, you can see a warning since the instructor is using v1 of the CLI.\n",
      "Solution description: To get around this, pass the argument ‘--cli-binary-format raw-in-base64-out’. This will encode your data string into base64 before passing it to kinesis\n",
      "Added by M\n",
      "\n",
      "Original Answer:\n",
      "Problem description:  You might get an error ‘Invalid base64’ after running the ‘aws kinesis put-record’ command on your local machine. This might be the case if you are using the AWS CLI version 2 (note that in the video 4.4, around 57:42, you can see a warning since the instructor is using v1 of the CLI.\n",
      "Solution description: To get around this, pass the argument ‘--cli-binary-format raw-in-base64-out’. This will encode your data string into base64 before passing it to kinesis\n",
      "Added by M\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question:\\n{course_piece['question']}\\n\")\n",
    "print(\"Top Retrieved Answer:\\n{}\\n\".format(result.points[0].payload['text']))\n",
    "print(\"Original Answer:\\n{}\\n\".format(course_piece['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167789d-ba50-49ee-a3be-8c7c917458e0",
   "metadata": {},
   "source": [
    "Now, searching a question that wasn't initially in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3f880f5-6bd1-4f0c-8714-7e53964f31b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\n",
      "Older news:[source1] [source2]\n"
     ]
    }
   ],
   "source": [
    "print(search(\"What if i submit homework late?\").points[0].payload['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef710a73-ba9f-479f-a470-3a77b73a1a0e",
   "metadata": {},
   "source": [
    "<h3> Step 7: Running a similarity search with filters</h3>\n",
    "\n",
    "Using Qdrant's custom vector index implementation, Filterable HSNW, we can get precise and scalable vector search results with filtering conditions.\n",
    "Using a 'must' filter ensures that all specified conditions are met for a data point to be included in the search results.\n",
    "Qdrant also supports other filter types such as 'should', 'must_not', 'range', and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be8cfc36-035b-4892-97d5-a48734375f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=3, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to enable filtering, we need to turn on indexing of payload fields.\n",
    "\n",
    "client.create_payload_index(\n",
    "    collection_name = collection_name,\n",
    "    field_name = 'course',\n",
    "    field_schema = 'keyword'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b9dc906-1de6-47a1-8748-95180ec43490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the search function\n",
    "\n",
    "def search_in_course(query, limit=1, course):\n",
    "    results = client.query_points(\n",
    "        collection_name = collection_name,\n",
    "        query = models.Document(      # embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text = query,\n",
    "            model = model_handle \n",
    "        ),\n",
    "        query_filter = models.Filter(   # filter by course name\n",
    "            must = [\n",
    "                 models.FieldCondition(\n",
    "                     key = 'course',\n",
    "                     match = models.MatchValue(value = course)\n",
    "                 )   \n",
    "            ]\n",
    "        ),\n",
    "        limit = limit,   # top closest matches\n",
    "        with_payload = True    #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcc7aef6-44f0-42df-b18d-d5c9a71a8560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depends on whether the form will still be open. If you're lucky and it's open, you can submit your homework and it will be evaluated. if closed - it's too late.\n",
      "(Added by Rileen Sinha, based on answer by Alexey on Slack)\n"
     ]
    }
   ],
   "source": [
    "print(search_in_course(\"What if i submit homework late?\", course = 'machine-learning-zoomcamp').points[0].payload['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211af0e-ef65-4d07-abc6-3e6d94ee7e71",
   "metadata": {},
   "source": [
    "<h3>Conclusion: </h3>\n",
    "\n",
    "A simple semantic search using Qdrant on FAQ documents has been completed.\n",
    "\n",
    "Next step is Hybrid Search - combining the strengths of keyword-based search and vector search.\n",
    "\n",
    "In many real-world applications, they work hand-in-hand, balancing the precision of keywords with the flexibility of embeddings to deliver the best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
